\chapter{Begriffe im Maschinellen Lernen}
\label{cha:Begriffe}

Diese Erklärung der Begriffe und Elemente verfolgt zwei Ziele.
Zum einen stellt dies Grundlage des gesamten Themas dar und soll für Interessierte die nicht so vertraut sind, eine Einführung in die Thematik bieten. 
Und zum anderen werden viele dieser Begriffe erläutert, welche noch häufig zum Einsatz kommen (u.A. Neuron, Aktivierungsfunktion, …).

\section{Data Science}

Data Science wird generell als die Extraktion von Wissen aus Daten bezeichnet. 
Dabei werden die Teilbereiche, Statistik und Mathematik, Computer Science und Machine Learning sowie einige weitere, in diesem Begriff zusammengefasst. 
Das Gebiet für sich wird auch als Berufstätigkeit bezeichnet, wobei meist spezialisierte Formen für die Berufsbezeichnung verwendet werden.\\

Damit Wissen aus Daten überhaupt extrahiert werden kann, muss ein ganzer Prozess durchlaufen werden. 
Dieser beginnt mit dem zusammentragen von Rohdaten aus der Realität, welche aber zu diesem Zeitpunkt noch keinen Zusammenhang offenbaren. 
Im zweiten Prozessschritt werden diese Daten meist umgebaut und neu sortiert wobei dieser Schritt nicht immer erforderlich ist. 
Auf die zurecht gelegten Daten besteht nun die Möglichkeit Modelle, Algorithmen sowie weitere Extraktionen durchzuführen. 
Die erneut extrahierten Daten werden in dem zweiten Prozessschritt als Ausgangsdaten verwendet. 
Auf diese Daten ausgeführte Modelle und Algorithmen liefern Ergebnisse die visuell dargestellt für eine größer Gruppe an Personen geeignet ist. 
Aus diesem gelernten Wissen besteht zusätzlich die Möglichkeit dieses zum Generieren von neuen Daten zu verwenden und neue Modelle zu entwickeln, die zum Beispiel Vorgänge in der Natur noch akkurater wiederspiegeln.

\section{Machine Intelligence}

Maschine Intelligenz ist ein Begriff der so an sich noch nicht Definiert worden ist. 
Einige namhafte Unternehmen wie Google Inc. und Microsoft Corporation bieten jeweils unterschiedliche Definitionen oder Beschreibungen. 
Dieser wird aber von allen ähnlich beschrieben und definiert. 
Es bezeichnet einen Überbegriff über das gesamte Gebiet mit Machine Learning, Künstlicher Intelligenz, Konversationsintelligenz und alle Themen die in näherer Beziehung dazu stehen. 

\section{Machine Learning}
\label{sec:Machine Learning}

Machine Learning definiert eine große Anzahl an Theorien und Umsetzungen von nicht explizit programmierten Abläufen. 
Diese wurden aus Studien in den Bereichen der Mustererkennung und Rechnerische Lerntheorien mit Künstlicher Intelligenz teilweise entwickelt. 
Dieses Gebiet umfasst im Jahr 2016 aber sehr viel mehr. 
So existieren zusätzlich Ansätze aus dem Bereich der Biologie wie zum Beispiel Neuronale Netzwerke, die dem Gehirn nach empfunden sind und Genetische Algorithmen die der Weiterentwicklung eines Lebewesen ähneln. 
Ein ganz andere Zugang wurde in der Sowjetunion verfolgte, mit sogenannte 'Support Vektor Machines', bei welchen man einen rein mathematischen Ansatz verfolgte.

\section{Neuronale Netzwerke}

Neuronale Netzwerke auch bekannt im Jahre 2016 unter dem Begriff 'Deep Learning'. \\

Die Theorie und die ersten Grundlagen wurden im Jahre 1943 von Warrn McCulloch und Walter Pitts geschaffen, die ein Modell entwickelten aber nicht die technischen Möglichkeiten hatten dieses umzusetzen.
Dieses basierte auf Mathematik und Algorithmen und führte zur 'Threshold Logik'. 
Durch den 'Backpropagation'-Algorithmus im Jahre 1975, wurden es möglich Netzwerke mit mehr als drei Ebenen zu trainieren. \\

Neuronale Netzwerke bestehen aus Neuronen die mit einander Verbunden sind und gemeinsam ein Netzwerk ergeben, welches dem Gehirn nachempfunden ist. 
Die Verbindungen sind nicht fest vorgegeben sondern können auch zum Beispiel Schleife bilden.

%TODO: you can do anything with it, if it can be designed as a function

\section{Neuron}
\label{sec:Neuron}

Abbildung ( Aufbau eines Neurons ) - TikZ Grafik \\

Ein Neuron wurde einer Nervenzelle in einem Gehirn nachempfunden und besteht aus:
\paragraph{Informationseingangsstrom} ist der Dateneingang, wobei ein Neuron ein bis theoretisch unendlich viele solcher Eingänge haben könnte. 
Dies hängt von der jeweiligen Architektur des Netzwerks ab.

\paragraph{Informationsgewichtung} bezeichnet die Gewichtung mit der, der Eingangsstrom gewertet wird. 
%Dies wird Gewichtung genannt. 
So wird ein Informationseingangsstrom mehr berücksichtigt oder nicht. 
Diese Gewichtung wird durch den Backpropagation-Algorithmus angepasst und nachjustiert.

\paragraph{Kernfunktion} bewirkt das Verarbeiten der gewichteten Informationseingänge. 
Im einfachsten Fall werden alle Werte summiert zu einem Wert. 
Es wäre aber möglich, jegliche Berechnung hier einfließen zu lassen, welche mehrere Werte verwendet und daraus einen Wert berechnet.

\paragraph{Aktivierungsfunktion} stellt den Ausgang eines Neuron dar. 
Dabei wird eine weitere Funktion auf das im Kern berechnete Ergebnis ausgeführt und führt dazu, dass ein Ergebnis noch stärker ausgeprägt weiter gegeben wird oder minimiert wird. 
Diese Aktivierungsfunktion ist meist die Sigmoid-Funktion oder eine Lineare-Funktion. 
%Wobei in den vergangen Jahren die Linearen-Funktionen häufiger zum Einsatz kommen.
\\

Die einfachste Repräsentation eines Neurons lässt sich mathematisch so darstellen.
Im Kern wird eine Summenberechnung durchgeführt. 
Dabei werden die Eingangswerte und deren Gewichtung mit einander multipliziert, sowie diese Ergebnisse aufsummiert.
Der griechische Buchstabe $\phi$ (phi) steht für die Aktivierungsfunktion des Neurons und stellt damit die Ausgabe des Neurons dar.
\begin{equation}
	f(x_i, w_i) := \phi ( \sum\limits_{i}{(w_i * x_i)})
\end{equation}


\section{Bias Neuron}
\label{sec:Bias Neuron}

Ein Bias definiert einen spezial Fall eines Neurons, welches keine Dateneingänge somit auch keine Gewichtung hat, sowie keine Berechnung im Kern durchführt. 
Dieses liefert nur einen Konstanten Wert aus wie zum Beispiel eine Eins. 
Durch die konstante Auslieferung wird auch die Aktivierungsfunktion überflüssig. 
Das Bias Neuron stellt somit einen konstanten Wert für das Netzwerk dar, beziehungsweise für die darauffolgende Ebene.

\section{Ebenen/Layer}
\label{sec:Layer}

Ebenen sind Zusammenschlüsse von Neuronen welche sich auf der selben Ebene befinden. 
Diese Neuronen sind aber nicht mit einander Verbunden, sondern bekommen Daten aus der Ebene davor und geben diese an die darauffolgende Ebene weiter. 
Diese Art wird \textbf{Hiddenlayer} bezeichnet. 
Jedes Netzwerk benötigt zusätzlich zwei weiter Ausprägungen an Ebenen. 
Diese sind:

\paragraph{Inputlayer} sind Ebenen die keine vorgeschaltete Ebene haben. 
Diese Ebene nimmt die Daten ohne Gewichtung auf und gibt sie verarbeitet an die darauffolgende Ebene weiter. 
In gewisser Weise stellt es einen Übergang zwischen der Welt außerhalb und des Neuronalen Netzwerkes dar.

\paragraph{Outputlayer} befindet sich am Ende eines Netzwerkes. 
Dieser Layer hat die Aufgabe die Daten nach außerhalb weiter zu geben anstatt an das darauffolgende Netzwerk. 
Hierbei werden die Informationen meist nur mehr für die Ausgabe hergerichtet. 
So wird zum Beispiel die Wahrscheinlich für jeder möglichen Ausgänge berechnet.
\\

Abbildung ( Aufbau eines Einfachen FeedForward NN) - TikZ Grafik

\section{Informationen Merken und wieder Erkennung}

Durch das Anpassen der Gewichtungen bei jedem Dateneingangsstrom mit Hilfe des Backpropagation-Algorithmus wird es möglich Zustände zu speichern und diese auch zu Merken. 
Dies führt dazu, dass sollte ein ähnlicher Dateneingang statt finden, wo zuvor schon ein ähnlicher in einem Trainingszyklus vorhanden war, dieser ähnliche erkannt wird. 
Dieser könnte somit möglicherweise zu der selben Kategorie gehört, wie der schon zuvor schon bekannte gemachte und gelernte Dateneingang.

\section{Backpropagation}

TODO: relative genau Algorithmus mit Aufgabe

\section{Allgemeine Probleme}

Neuronale Netzwerke sind nicht Fehler und Problem los und sind nicht die Lösung auf jegliche Frage die es auf der Welt gibt. 
Es existieren bekannte Probleme für die es Lösungen oder Lösungsansätze gibt. 
Es existieren aber auch noch genügend andere Probleme, welche noch nicht festgestellt wurden oder als solche noch nicht erkannt worden sind. \\

Diese Arbeit wird auf die bekanntesten Probleme eingehen und beschreiben und auch Lösungen oder mögliche Lösungsansätze beinhalten. 

\subsection{Overfitting}

Overfitting bezeichnet ein Problem welches nicht nur Machine Learning betrifft sondern auch Menschen und andere Lebewesen. 
Zum Beispiel ein Student lernt auf eine Prüfung und ist im Besitz einer Klausur aus einem Vorjahr. 
Nach öfteren durchspielen der Fragen und sich selbst testen, befindet er sich in der Lage diese Klausur mit einer sehr hohen Wahrscheinlichkeit zu bestehen. 
Dabei hat sich die Klausur in seinem Gehirn eingeprägt aber nicht das Stoffgebiet zu welchem er eine Klausur schreiben muss. 
Das Problem wird als Overfitting bezeichnet und beschreibt das etwas gemerkt wurde aber nicht gelernt worden ist und somit eine Abwandlung von Informationen nicht wiedererkannt werden.

\subsection{Datensätze}

TODO: jeder datensat ist unterschiedlich -> neue Daten = neues Netzwerk

\section{Trainieren}

TODO

\subsection{Supervised Trainieren}

TODO

\subsection{Unsupervised Trainieren}

TODO

\section{Domänenklassen}
\label{sec:Domänenklassen}

Neuronale Netzwerk können sehr vielseitig eingesetzt werden. 
Grundsätzlich lässt sich jedes Problem, welches als Funktion repräsentiert werden kann, durch ein Neuronales Netzwerk approximieren. \\

In dieser Arbeit werde sieben Hauptdomänen erklärt und beschreiben, in welchen Neuronale Netzwerke öfters zum Einsatz kommen und eingesetzt werden.

\subsection{Clustering}
\label{subsec:Clustering}

Clustering Problem bezeichnen das Einordnen von Daten in Klassen oder Gruppierungen. 
Diese Gruppierungen können von einem Netzwerk selbst definiert werden oder festgelegt werden in wie viele Gruppen die Daten eingeordnet werden sollen. 
Diese Netzwerke agieren unsupervised und besitzen meist die Möglichkeit sich nach dem Trainieren, sich noch selbst weiter anzupassen. 
Dies erlaubt dem Netzwerk auf sich ändernde Daten anzupassen und das Clustern und Gruppieren weiter zu führen ohne ein neues Netzwerk erstellen zu müssen.

\subsection{Regression}
\label{subsec:Regression}

TODO

\subsection{Classification}
\label{subsec:Classification}

Classification Problem ist in gewisser Weise das Gegenstück zum Regression Problem. 
Hier werden Daten dem Netzwerk übergeben und dieses muss vorhersagen zu welcher Klasse sie gehören. Dies wird in einer supervised Umgebung durchgeführt. 
Die Klassen für die Vorhersage sind vorab schon bekannt und können im den Daten aus dem Outputlayer des Netzwerks  verglichen werden und infolge Justierungen durchgeführt werden.

\subsection{Predict}
\label{subsec:Predict}

Predict Problemstellungen kommen im Kontext von Business beziehungsweise von E-Business zur Anwendung. 
Hier muss anhand von meist Zeit gesteuerten Ereignisse eine Vorhersage getroffen werden. 
Zum Beispiel an der Börse ändern sich täglich die Kurse teilweise so rasch, dass es für Menschen praktisch nicht mehr möglich ist diesen zu Folgen. 
Im Falle der Börse sind nun aber Zeitlich gestützte Kurse aus der Vergangenheit verfügbar. 
Diese werden als Trainingsset für ein Netzwerk verwendet, um den nächsten Tag möglicherweise vorherzusagen. 

\subsection{Robotics}
\label{subsec:Robotics}

Im Bereich von Robotics entstehen häufig zu große Datenmengen. 
Diese Datenmengen müssten von einem Menschen analysiert werden. 
Daraus würde ein Algorithmus entstehen, wobei die Analyse sowie Entwicklungsphase zu viel Zeit in Anspruch nimmt. 
Netzwerke verwenden im Grunde die Sensorinformationen und steuern damit Motoren. 
Diese kann von Anfang an durchgeführt werden, sowie automatisiert.

\subsection{Computer Vision}
\label{subsec:Cumputer Vision}

Computer Vision zielt darauf ab, einem Computer das Sehen und Verstehen von Bildern zu ermöglichen. 
Diese Technik findet im Jahr 2016 schon häufig Einsatz. 
So werden automatisiert Bilder analysiert, beschrieben sowie auch klassifiziert. 
Diese Dienste werden auch Kommerziell eingesetzt und auch angeboten. 
In autonom gesteuerten Fahrzeugen findet dies auch Verwendung, um Objekte zu Erkennen und zu Verstehen. 
So muss zum Beispiel ein Verkehrszeichen von einem Passanten unterschieden werden können.

\subsection{Optimization}
\label{subsec:Optimization}

Optimization bezieht sich auf eines der Grundprobleme der Informationstechnologie. 
So werden immer bessere schnellere Algorithmen entwickelt, welcher konkrete Probleme noch effizienter Lösen können. 
Durch das Thema BigData entstand ein Problem, sodass selbst sehr effiziente Algorithmen einige Problemstellungen nicht mehr in konstanter oder adäquater Zeit lösen können. 
Das 'Salesman' Problem gehört zu diesen Problemen. 
Durch Optimization wird in konstanter Zeit eine Lösung ermittelt, welche nicht die beste Lösung repräsentiert. 
Diese Lösung liegt aber im Rahmen von einer bestimmten definierten Toleranz und könnte als Lösung verwendet werden.

%\cite{AI3}

\section{Neuronale Netzwerktypen}

Aus der Zeit heraus haben sich diverse gut funktionierende Neuronale Netzwerktypen gebildet beziehungsweise sind entwickelt und erforscht worden. 
Diese Netzwerktypen definieren Richtlinien oder Ansätze zu möglichen Netzwerken, welche aber nicht komplett übernommen werden müssen sonder einen kreativen Spielraum ermöglichen. \\

In dieser Arbeit werde die wichtigsten Typen und ihre Eigenschaften erklärt. 
Für die folgenden Punkte ist es erforderlich ein Grundverständnis für Neuronale Netzwerk sowie über ihre Funktionsweise zu besitzen, sollte dies nicht der Fall sein - Punkt \ref{sec:Machine Learning} bis \ref{sec:Domänenklassen}.

\subsection{FeedForward}
\label{subsec:FeedForward}

FeedForward Netzwerke (FFN) waren bis for einigen Jahren noch der Standard.
Auf ihnen basieren einige andere Typen von Netzwerken, die bekanntesten werden in dieser Arbeit noch behandelt.
Ein FFN passiert auf den Grundlagen eines Neurons \ref{sec:Neuron}, sowie dem ausbauen dieses zu Ebenen mit mehreren Neuronen \ref{sec:Layer}.
So ein Netzwerk besitzt einen Inputlayer, einen Hiddenlayer sowie einen Outputlayer.
Sobald das Netzwerk mehrere Hiddenlayer aufweist wird es als Deep FeedForward Netzwerk \ref{subsec:Deep Feedforward} bezeichnet.
Das FFN weist dabei eine Charakteristik auf, indem dass der Datenfluss eindeutig definiert ist. 
Der Datenfluss beginnt bei dem Inputlayer und endet bei dem Outputlayer ohne dass ein Datenrückfluss zum Beispiel von dem Hiddenlayer in den Hiddelayer vorhanden ist.
Dies würde eine Rekursion oder einem Kurzzeitgedächtnis entsprechen.
Die einzelnen Ebenen müssen dabei aber nicht voll verbunden sein, sondern die Vernetzung kann selbst bestimmt werden.

\subsection{Self-Organizing Map}

Self-Organizing Map (SOM) findet vor allem im Bereich der Classification  \ref{subsec:Classification} Verwendung und wurden von Kohonen (1988) erfunden. 
Es ist nicht erforderlich einer SOM die Information zu geben, in wie viele Gruppen oder Klassen die Daten unterteilt werden sollen. 
Dadurch gehören es zu den Systemen, welche unsupervised trainiert werden. 
Außerdem besitzen es die Möglichkeit, sich auch nach der Trainingsphase auf sich ändernde Eingangsdaten anzupassen. 
Kohonen entwarf die SOM mit zwei Ebenen, ein Inputlayer und ein Outputlayer ohne Hidenlayer. 
Der Inputlayer propagiert Muster an den Outputlayer, wo der Dateneingang gewichtet wird. 
In dem Outputlayer gewinnt das Neuron, welches den geringsten Abstand zu den Eingangsdaten hat.
Dies geschieht durch das Berechnen der euklidischen Distanz. 
Diese Art von Netzwerk kommt ohne Bias Werte \ref{sec:Bias Neuron} aus und es kommen ausschließlich Lineare Aktivierungsfunktionen zur Verwendung.



\subsection{Hopfield}

\subsection{Boltzmann Machine}

\subsection{Deep Belief Network}

\subsection{Deep Feedforward}
\label{subsec:Deep Feedforward}

\subsection{NEAT}

\subsection{CPPN}

\subsection{HyperNEAT}

\subsection{Convolutional neural network}

\subsection{Elman Network}

\subsection{Jordan Network}

\subsection{Recurrent Network}

\section{Domänen und Typen Matrix}

\section{Tensorflow Typen Unterstützung}
