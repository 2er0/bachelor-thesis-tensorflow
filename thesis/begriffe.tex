\chapter{Begriffe im Maschinellen Lernen}
\label{cha:Begriffe}

Diese Erklärung der Begriffe und Elemente verfolgt zwei Ziele: 
Zum einen stellt dies die Grundlage des gesamten Themas dar und soll für Interessierte, die nicht so vertraut sind, eine Einführung in die Thematik bieten. 
Und zum anderen werden viele der Begriffe erläutert, die in dieser Arbeit noch häufig zum Einsatz kommen werden (u.A. Neuron, Aktivierungsfunktion, …).

\section{Data Science}

Data Science wird generell als die Extraktion von Wissen aus Daten bezeichnet. 
Dabei werden die Fachbereiche Statistik und Mathematik, Informatik und Machine Learning, sowie einige weitere zu diesem Begriff zusammengefasst. 
Das Gebiet für sich wird auch als Berufstätigkeit bezeichnet, wobei meist spezialisierte Formen für die Berufsbezeichnung verwendet werden. \newline

\noindent 
Damit Wissen aus Daten überhaupt extrahiert werden kann, muss ein ganzer Prozess durchlaufen werden. 
Dieser beginnt mit dem Zusammentragen von Rohdaten aus der Realität, welche zu diesem Zeitpunkt noch keinen Zusammenhang offenbaren. 
Im zweiten Prozessschritt werden diese Daten meist umgebaut und neu sortiert, wobei dieser Schritt nicht immer erforderlich ist. 
Auf diese zurecht gelegten Daten besteht nun die Möglichkeit, Modelle, Algorithmen sowie weitere Extraktionen durchzuführen. 
Die erneut extrahierten Daten werden in weiterer Folge als Ausgangsdaten verwendet. 
Auf diese Daten ausgeführte Modelle und Algorithmen liefern Ergebnisse, die visuell dargestellt, für eine größere Gruppe von Personen geeignet sind. 
Aus diesem gelernten Wissen besteht zusätzlich die Möglichkeit, dieses zum Generieren von neuen Daten zu verwenden und neue Modelle zu entwickeln, die zum Beispiel Vorgänge in der Natur noch akkurater widerspiegeln.

\section{Machine Intelligence}

Machine Intelligence ist ein Begriff, der noch nicht eindeutig definiert worden ist, aber schon Verwendung findet. 
Einige namhafte Unternehmen wie Google Inc. und Microsoft Corporation bieten jeweils unterschiedliche Definitionen oder Beschreibungen. 
Die Definitionen dieser Firmen weichen nur unwesentlich voneinander ab.
Dieser Begriff wird als Überbegriff für das gesamte Gebiet von Machine Learning, Künstlicher Intelligenz, Konversationsintelligenz und allen Bereichen, die in näherer Beziehung dazu stehen, verwendet. 

\section{Machine Learning}
\label{sec:Machine Learning}

Machine Learning definiert eine große Anzahl an Theorien und Umsetzungen von nicht explizit programmierten Abläufen. 
Diese wurden aus Studien in den Bereichen der Mustererkennung und der rechnerischen Lerntheorie mit Künstlicher Intelligenz teilweise entwickelt. 
Dieses Gebiet umfasste im Jahr 2016 aber sehr viel mehr. 
So existieren zusätzliche Ansätze aus dem Bereich der Biologie, wie zum Beispiel Neuronale Netzwerke, die dem Gehirn nachempfunden sind und genetische Algorithmen, die der Weiterentwicklung eines Lebewesens ähneln. 
Ein ganz anderer Zugang wurde in der Sowjetunion verfolgt, mit sogenannten 'Support Vektor Machines', bei welchem man einen rein mathematischen Ansatz anstrebte \cite{lampropoulos2015machine}. 

\section{Neuronale Netzwerke}

Die Theorie und die ersten Grundlagen wurden im Jahre 1943 von Warren McCulloch und Walter Pitts geschaffen, die ein Modell entwickelten, jedoch nicht die technischen Möglichkeiten hatten dieses umzusetzen.
Dieses führte zur 'Threshold Logik', welche bestimmt, ab wann und wie stark ausgeprägt etwas weitergegeben wird \cite{rojas2013neural}.
Durch die Entwicklung des 'Backpropagation'-Algorithmus (siehe \ref{sec:Backpropagation}) ist es möglich, Netzwerke mit mehr als drei Ebenen zu trainieren.
Neuronale Netzwerke bestehen aus Neuronen, die miteinander verbunden sind und gemeinsam ein Netzwerk ergeben \cite{AI3}.  

\subsection{Neuron}
\label{sec:Neuron}

\begin{figure}
\centering

\begin{tikzpicture}
	
	\node[neuron] (a) {};
	\node[neuron,below=of a] (b) {};
	\node[neuron,below=of b] (c) {};
	
	\node[neuron,right=of b] (root) {$\phi(\sum)$};
	
	\node[right=of root] (out) {};

	\node[group,fit={(a) (b) (c)}] (gr1) {};
	\draw[conn] (a) -- (root);
	\draw[conn] (b) -- (root);
	\draw[conn] (c) -- (root);
	\draw[conn] (root) -- (out);

\end{tikzpicture}

	\caption{Neuron mit Eingang, Kernfunktion, Aktivierungsfunktion}
	\label{fig:Neuron}
\end{figure}

Ein Neuron wurde einer Nervenzelle in einem Gehirn mit den folgenden Bestandteilen nachempfunden:
\paragraph{Informationseingangsstrom} ist der Dateneingang, wobei ein Neuron ein bis theoretisch beliebig viele solcher Eingänge haben kann. 
Dies hängt von der jeweiligen Architektur des Netzwerks ab.

\paragraph{Informationsgewichtung} bezeichnet die Gewichtung mit der der Eingangsstrom gewertet wird. 
So wird ein Informationseingangsstrom mehr oder weniger berücksichtigt. 
Diese Gewichtung wird durch den Backpropaga-tion-Algorithmus angepasst und nachjustiert.

\paragraph{Kernfunktion} bewirkt das Verarbeiten der gewichteten Informationseingänge. 
Im einfachsten Fall werden alle Werte aufsummiert. 
Es wäre aber möglich, jegliche Berechnung hier einfließen zu lassen, welche mehrere Werte verwendet und daraus einen neuen Wert berechnet.

\paragraph{Aktivierungsfunktion} berechnet den Ausgang eines Neurons. 
Dabei wird eine weitere Funktion auf das im Kern berechnete Ergebnis ausgeführt, das dazu führt, dass ein Ergebnis noch stärker ausgeprägt weitergegeben wird oder minimiert wird, beziehungsweise in einen Wertebereich eingepasst wird. 
Diese Aktivierungsfunktion ist meist die Sigmoid-Funktion oder eine lineare Funktion, welche in der Abbildung \ref{fig:Aktivierungsfunktion} zu erkennen sind.

\begin{figure}[ht!]
\centering
\subfloat{
\resizebox {0.5\linewidth} {5cm} {
	\begin{tikzpicture}
	\begin{axis}

		\addplot[blue, no markers] expression { 1/(1+exp(-x) };c

	\end{axis}
	\end{tikzpicture}
}
}
\subfloat{
\resizebox {0.5\linewidth} {5cm} {
	\begin{tikzpicture}
	\begin{axis} [xmin=-1, xmax=1]

		\addplot[blue, no markers] expression { x };

	\end{axis}
	\end{tikzpicture}
}
}
	\caption{Basisaktivierungsfunktionen: (l) eine Sigmoid-Funktion, (r) eine lineare Funktion}
	\label{fig:Aktivierungsfunktion}
\end{figure}

\noindent 
Die einfachste Repräsentation eines Neurons lässt sich mathematisch folgendermaßen darstellen.
Im Kern wird eine Summenberechnung durchgeführt. 
Dabei werden die Eingangswerte und deren Gewichtung miteinander multipliziert, sowie diese Ergebnisse aufsummiert.
Der griechische Buchstabe $\phi$ (phi) steht für die Aktivierungsfunktion des Neurons und stellt damit die Ausgabe des Neurons dar.
\begin{equation}
	f(x, w) := \phi ( \sum\limits_{i}{w_i * x_i})
	\label{eq:Aktivierungsfunktion}
\end{equation}

\paragraph{Bias Neuron} 
\label{sec:Bias Neuron}
definiert einen Spezialfall eines Neurons, welches keine Dateneingänge und somit auch keine Gewichtung hat und keine Berechnung im Kern durchführt. 
Dieses liefert nur einen konstanten Wert, wie zum Beispiel eine $1$. 
Durch die konstante Auslieferung wird auch die Aktivierungsfunktion überflüssig. 
Das Bias Neuron stellt somit einen stetigen Wert für das Netzwerk dar, beziehungsweise für die darauffolgende Ebene.

\section{Ebenen/Layer}
\label{sec:Layer}

Ebenen sind Zusammenschlüsse von Neuronen, welche sich auf derselben Stufe befinden. 
Diese Neuronen sind aber nicht miteinander verbunden, sondern bekommen Daten aus der Ebene davor und geben diese an die darauffolgende Ebene weiter. 
Dieser Typ wird \textbf{Hiddenlayer} bezeichnet. 
Jedes Netzwerk benötigt zusätzlich zwei weitere Ausprägungen an Ebenen. 
Diese sind:

\paragraph{Inputlayer} stellt den Übergang zwischen der Welt außerhalb des Neuronalen Netzwerks und dem Netzwerk dar.
Diese Ebene nimmt die Daten ohne Gewichtung auf und gibt sie an die darauffolgende Ebene weiter. 

\paragraph{Outputlayer} befindet sich am Ende eines Netzwerkes. 
Dieser Layer hat die Aufgabe, die Daten nach außen, oder an das darauffolgende Netzwerk weiterzugeben. 
Hierbei werden die Informationen meist nur mehr für die Ausgabe aufbereitet. 
In manchen Netzwerken existieren keine Outputlayer in diesem Sinne, sondern ein Layer, der als Hiddenlayer und Outputlayer fungiert. 
Dies ist der Fall, wenn nur zwei Layer sich im Netzwerk befinden und einer davon vom Inputlayer eingenommen wird.
\\

\begin{figure}
\centering

\begin{tikzpicture}

	\node[neuron] (in) {I};

	\node[neuron,right=of in] (1a) {N};
	\node[neuron,below=of 1a] (1b) {N};
	\node[io,below=of 1b] (b1) {B};
	
	\node[group,fit={(1a) (1b) (b1)},right=of in] (gr1) {};
	
	\node[neuron,right=of 1a] (2a) {N};
	\node[neuron,below=of 2a] (2b) {N};
	\node[io,below=of 2b] (b2) {B};
	
	\node[group,fit={(2a) (2b) (b2)},right=of 1a] (gr2) {};
	
	\node[neuron,right=of 2a] (3a) {N};
	\node[neuron,below=of 3a] (3b) {N};
	\node[io,below=of 3b] (b3) {B};
	
	\node[group,fit={(3a) (3b) (b3)},right=of 2a] (gr3) {};
	
	\node[neuron,right=of 3b] (out) {O};
	
	\draw[conn] (in) -- (1a);
	\draw[conn] (in) -- (1b);

	\draw[conn] (1a) -- (2a);
	\draw[conn] (1a) -- (2b);
	
	\draw[conn] (1b) -- (2a);
	\draw[conn] (1b) -- (2b);

	\draw[conn] (b1) -- (2a);
	\draw[conn] (b1) -- (2b);
	
	
	\draw[conn] (2a) -- (3a);
	\draw[conn] (2a) -- (3b);
	
	\draw[conn] (2b) -- (3a);
	\draw[conn] (2b) -- (3b);

	\draw[conn] (b2) -- (3a);
	\draw[conn] (b2) -- (3b);
	
	
	\draw[conn] (3a) -- (out);
	\draw[conn] (3a) -- (out);
	
	\draw[conn] (3b) -- (out);
	\draw[conn] (3b) -- (out);

	\draw[conn] (b3) -- (out);
	\draw[conn] (b3) -- (out);

\end{tikzpicture}

	\caption{Einfaches Neuronales FeedFordward Netzwerk}
	\label{fig:SimpleFeedForwardNetwork}
\end{figure}
\phantom \newline

\noindent 
In der Abbildung \ref{fig:SimpleFeedForwardNetwork} ist ein einfachen FeedFordward Netzwerk abgebildet.
Dieses beinhaltet alle Typen mit Input-, Outputlayer und voll vernetzte Layer mit Neuronen und Bias Neuron. 

\section{Informationen Merken und Wiedererkennung}

Durch das Anpassen der Gewichtungen bei jedem Dateneingangsstrom mit Hilfe des Backpropagation-Algorithmus ist es möglich, Zustände zu speichern und diese auch zu merken. 
Sollte ein ähnlicher Dateneingang stattfinden, wo zuvor schon einer vorhanden war, dann sollte dieser ähnlich behandelt werden.
Dieser kann möglicherweise zu derselben Kategorie gehören, wie der zuvor schon bekannt gemachte und gelernte Dateneingang.

\section{Konvergieren im Maschinellen Lernen}
\label{sec:Konvergieren}

Konvergieren im Maschinellen Lernen bezeichnet das Minimieren der Fehlerquote gegen $0$.
Die Fehlerquote wird dabei als Error bezeichnet und ist ausschlaggebend für den Lernprozess.
Ein Error von $0$ würde bedeuten, dass das Netzwerk keinen Fehler machen würde.
Für die Feststellung des Fehlers gibt es diverse Funktionen, wie zum Beispiel die 'Mean-Square-Error'-Methode.

\section{Backpropagation}
\label{sec:Backpropagation}

Bis zum Jahre 1986 gab es keine automatisierte Möglichkeit, die Gewichtungen in einem Netzwerk automatisch anzupassen.
In diesem Jahre entwickelten Rumelhart, Hinton \& Williams eine mögliche Lösung, welche sehr ähnlich zu anderen Ansätzen von früher war \cite{hecht1988theory}.
Die zentrale Idee in ihrer Lösung liegt darin, die Abweichung des produzierten Ergebnisses zum wirklich erwarteten Ergebnis zu bestimmen. 
Aufgrund dieses Fehlers lassen sich im Anschluss die Gewichtungen im Netzwerk vom Ende zum Anfang nachjustieren. 
Diese Technik ermöglichte damit Netzwerke mit verschachtelten Schichten zu konstruieren und auch zu trainieren.

\paragraph{Lernrate} skaliert den Lernprozess, mit der Auswirkung, ob schneller oder langsamer gelernt wird.
Eine Lernrate unter $0$ würde die Lerngeschwindigkeit stark verlangsamen und ist somit nicht sinnvoll. 
Ein Wert über $1$ würde eine hohe Lerngeschwindigkeit zur Folge haben. 
Eine zu hohe Rate würde nicht zum Konvergieren führen, sondern zum Springen.

\paragraph{Momentum} stellt wie die Lernrate eine Skalierung des Lernprozesses dar.
Dabei werden mit dem definierten Faktor die früheren Gewichtsupdates berücksichtigt. 
Dies führt dazu, dass lokale Tiefpunkte überwunden werden können und das System doch zum globalen Tiefpunkt konvergiert.

\section{Trainieren}

\paragraph{Überwachtes Trainieren} definiert, dass die Daten, welche zur Verfügung stehen aus zwei Teilen bestehen.
Erstens aus den Daten selbst, aus welchen gelernt und verstanden werden soll.
Zweitens aus den Ergebnissen, zu welchen das Netzwerk kommen sollte, welche meistens als Lable bezeichnet werden. 
In dieser Situation liefert das Netzwerk ein Ergebnis, welches mit dem erwarteten Wert verglichen werden kann.
Dieser Unterschied wird zum Feststellen des Fehlers verwendet, welcher besagt, wie inkorrekt das Ergebnis ist.
Des Weiteren wird dieser Fehlerwert für die Backpropagation benötigt.

\paragraph{Unüberwachtes Trainieren} kommt dann zu tragen, wenn nur Daten zum Trainieren zur Verfügung stehen.
Der erwartete Ausgang ist unbekannt.
Diese Strategie wird in Fällen von Clustering (\ref{subsec:Clustering}) verwendet.
Dabei sollen nicht bekannte Gruppen von zusammengehörenden Daten identifiziert werden. 
Self-Organizing Maps (\ref{subsec:SelfOrganizingMap}) entdecken zusammengehörende Muster und geben diese in einer Grafik zur weiteren Interpretation weiter. 
Diese Technik ist insbesonders interessant, da einem Netzwerk nie erklärt worden ist, warum etwas so ist. 
Es steht damit in Relation zu einem natürlichen Lernprozess, wie bei einem Menschen.

\section{Allgemeine Probleme}
\label{sec:AllgeProb}

Ein Grundsatz von neuronalen Netzwerken ist, dass sie nicht jede Frage dieser Welt beantworten können, sondern nur dies durchführen, wofür sie konstruiert wurden. 
Das Entwickeln eines neuen Netzwerks ist eine sehr schwierige und eine lang andauernde Aufgabe. 
Dabei können Fehler auftreten, wie Overfitting, aber auch vom Entwickler verursacht sein können. \\

\noindent
Diese Arbeit wird auf die bekanntesten Probleme eingehen und auch Lösungen oder mögliche Lösungsansätze beinhalten. 

\paragraph{Overfitting} bezeichnet ein Problem, welches nicht nur maschinelles Lernen betrifft, sondern auch Menschen und andere Lebewesen. 
Ein Student lernt zum Beispiel für eine Prüfung und ist im Besitz einer Klausur aus einem Vorjahr. 
Nach öfterem Durchspielen der Fragen und laufenden Selbsttests, befindet er sich in der Lage diese Klausur mit einer sehr hohen Wahrscheinlichkeit zu bestehen. 
Dabei hat sich die Klausur in seinem Gehirn eingeprägt, aber nicht das Stoffgebiet zu welchem er eine Klausur schreiben muss. 
Das Problem wird als Overfitting bezeichnet und beschreibt, dass etwas gemerkt wurde, aber nicht gelernt worden ist und somit eine Abwandlung von Informationen nicht wiedererkannt wird.

\paragraph{Daten} die zum Trainieren von Netzwerken verwendet werden, können selbst ein Problem darstellen.
Eine zu geringe Menge an Daten stellt den Entwickler vor das Problem, dass er für diese Daten ein akkurates Netzwerk entwickeln kann, dieses aber im weiteren Verlauf nicht die gewünschten Resultate liefern wird.
Zusätzlich kann es sein, dass die zur Verfügung gestellten Daten selbst nicht vollständig sind und somit wieder nur ein Subset verwendet werden kann. \\

\section{Domänenklassen}
\label{sec:Domänenklassen}

Neuronale Netzwerke können sehr vielseitig eingesetzt werden. 
Grundsätzlich lässt sich jedes Problem, welches als Funktion repräsentiert werden kann, durch ein Neuronales Netzwerk approximieren. \\

\noindent
In dieser Arbeit werden sieben Hauptdomänen erklärt und beschrieben, welche von Heaton \cite{AI3} definiert wurden. 

\subsection{Clustering}
\label{subsec:Clustering}

Das Clustering Problem bezeichnet das Einordnen von Daten in Klassen oder Gruppierungen. 
Diese Gruppierungen können von einem Netzwerk selbst definiert werden oder manuell festgelegt werden. 
Im Falle einer Self-Organiz-ing-Map werden die Gruppierungen selbst durch das System festgelegt.

\subsection{Regression}
\label{subsec:Regression}

Regression beschreibt den Fall, in welchem Rohdaten generiert werden und diese so verwendet werden. 
Dies kann im Sinne einer Klassifikation verstanden werden mit dem Unterschied, dass die Anzahl der Klassen unendlich ist, wie die der Reellen Zahlen von $[0 - 1]$. 
Ein Anwendungsfall ist das Finden einer zugrundeliegenden Funktion, bei der nur Resultate dieser Funktion vorliegen. 
So gibt es Abläufe in der Natur, welche schwer in einer Funktion festgehalten werden können. 
In diesem Fall lässt sich ein Netzwerk mit den Aktionen und Reaktionen trainieren und erhält eine Approximation der Vorgänge \cite{bishop2006pattern}.

\subsection{Klassifikation}
\label{subsec:Classification}

Bei der Klassifikation werden die Ergebnisse einer Regression, welche meist als Gleitkommazahl vorliegen, auf eine bestimmte Anzahl an Klassen übertragen. 
Der Unterschied liegt im Ergebnis, welches produziert wird.  
Hier werden Daten dem Netzwerk übergeben und dieses muss vorhersagen, zu welcher Klasse sie gehören. Dies wird in einer überwachten Umgebung durchgeführt. 
Die Klassen für die Vorhersage sind vorab schon bekannt und können mit den Daten aus dem Outputlayer des Netzwerks verglichen werden und infolge Justierungen durchgeführt werden \cite{AI3}. \\

\noindent
Ergebnisse einer Klassifikation sagen aus, mit welchem prozentualen Anteil etwas auf den gegebenen Input zutrifft. 
Das Gesamtergebnis ergibt immer 100 Prozent. 
Das Ergebnis bei einer Regression wird dabei nicht in Prozent angegeben, sondern stellt einen konkreten Wert dar.

\subsection{Predict}
\label{subsec:Predict}

Predict-Problemstellungen kommen im Kontext von Business, beziehungsweise von E-Business zur Anwendung. 
Hier muss anhand von meist zeitgesteuerten Ereignissen eine Vorhersage getroffen werden. 
Zum Beispiel an der Börse ändern sich täglich die Kurse relativ rasch, sodass es für Menschen praktisch nicht mehr möglich ist, diese zu verfolgen. 
Im Falle der Börse sind Aktienkurse mit zeitlichem Verlauf aus der Vergangenheit verfügbar. 
Diese können als Trainingsdaten für ein Netzwerk verwendet werden, um den nächsten Tag möglicherweise vorherzusagen. 

\subsection{Robotics}
\label{subsec:Robotics}

Auch bekannt unter dem Namen Robot-Learning. 
Dabei lernen Roboter eigenständig neue Techniken oder passen sich automatisch ihrer Umgebung an. 
Eines der Kernprobleme dabei ist, dass in Echtzeit etwas zur selben Zeit gelernt werden muss, aber auch Aktionen eingeleitet werden müssen, wie das Steuern von Motoren, um zum Beispiel nicht umzufallen.

\subsection{Computer Vision}
\label{subsec:Cumputer Vision}

Computer Vision zielt darauf ab, einem Computer das Sehen und Verstehen von Bildern zu ermöglichen. 
Diese Technik findet im Jahr 2016 schon häufig Einsatz. 
So werden automatisiert Bilder analysiert, beschrieben sowie auch in Gruppen nach diversen Kategorien eingeordnet, wie zum Beispiel nach Gesichtsausdrücken.
Solche Dienste werden auch kommerziell eingesetzt und angeboten. 
In autonom gesteuerten Fahrzeugen findet diese Technologie bereits Verwendung, um Objekte zu erkennen und zu verstehen. 
So muss zum Beispiel ein Verkehrszeichen von einem Passanten unterschieden werden können.

\section{Neuronale Netzwerktypen}

In den letzten Jahren haben sich diverse gut funktionierende neuronale Netzwerktypen gebildet, beziehungsweise sind entwickelt und erforscht worden. 
Diese Netzwerktypen definieren Richtlinien oder Ansätze zu möglichen Netzwerken, welche aber nicht komplett übernommen werden müssen, sondern einen kreativen Spielraum ermöglichen. \\

\subsection{FeedForward}
\label{subsec:FeedForward}

FeedForward Netzwerke (FFN) waren bis vor einigen Jahren noch der Stand der Forschung.
Auf ihnen basieren einige andere Typen von Netzwerken, die bekanntesten werden in dieser Arbeit noch behandelt.
Ein FFN basiert auf den Grundlagen eines Neurons, sowie ihrem Ausbau zu Ebenen mit mehreren Neuronen.
So ein Netzwerk besitzt einen Inputlayer, einen Hiddenlayer sowie einen Outputlayer.
Sobald das Netzwerk eine große Anzahl an Hiddenlayer aufweist, wird es als Deep FeedForward Netzwerk (\ref{subsec:DeepFeedForward}) bezeichnet.
Das FFN weist dabei eine Charakteristik auf, in der der Datenfluss eindeutig definiert ist. 
Der Datenfluss beginnt beim Inputlayer und endet beim Outputlayer, ohne dass ein Datenrückfluss zum Beispiel vom Hiddenlayer in den vorhergehenden Hiddenlayer vorhanden ist.
Dies würde einer Rekursion oder einem Kurzzeitgedächtnis entsprechen.
Die einzelnen Ebenen müssen dabei aber nicht voll verbunden sein, die Vernetzung kann selbst bestimmt werden.

\subsection{Self-Organizing Map}
\label{subsec:SelfOrganizingMap}

Self-Organizing Map (SOM) findet vor allem im Bereich der Classification Verwendung und wurde von Kohonen (1988) erfunden. 
Es ist nicht erforderlich einer SOM die Information zu geben, in wie viele Gruppen oder Klassen die Daten unterteilt werden sollen. 
Dadurch gehört sie zu den Systemen, welche unsupervised trainiert werden. 
Außerdem besitzen sie die Möglichkeit, neue Daten weiter zu klassifizieren und dies über die Trainingsphase hinaus. 
Kohonen entwarf die SOM mit zwei Ebenen, einem Inputlayer und einem Outputlayer ohne Hiddenlayer. 
Der Inputlayer propagiert Muster an den Outputlayer, wo der Dateneingang gewichtet wird. 
Im Outputlayer gewinnt das Neuron, welches den geringsten Abstand zu den Eingangsdaten hat.
Dies geschieht durch das Berechnen der euklidischen Distanz. 
Diese Art von Netzwerk kommt ohne Bias Neuron aus und es kommen ausschließlich lineare Aktivierungsfunktionen zur Verwendung.


\subsection{Hopfield Neuronal Network}

Ein Hopfield Neuronal Network (HNN) \cite{demuth2014neural} ist ein einfaches Netzwerk, welches aus einem Layer besteht. 
In diesem Layer sind alle Neuronen mit jedem anderen Neuron verbunden. 
Dieses Muster wurde von Hopfield (1982) erfunden. 
Im Gegensatz zu anderen Netzwerken können Hopfield Netzwerke in einer Matrix abgebildet werden, in welcher die Gewichtung zu den einzelnen Neuronen abgebildet werden. 
Das Problem bei diesem Typ ist, dass jedes Neuron auf dem Status des anderen aufbaut.
Dies stellt ein Problem für die Reihenfolge der Berechnung dar, was zu einem nicht stabilen Zustand führt.
Durch das Hinzugeben einer Energiefunktion kann festgestellt werden, in welchem Zustand sich das Netzwerk befindet. 
Hiermit kann ein Haltepunkt definiert werden, ab welchem keine Trainingsiteration mehr durchlaufen werden soll. 

\subsection{Boltzmann Machine}

Im Jahre 1985 stellten Hinton \& Sejnowski \cite{Hinton:Boltzman:2007} das erste Mal eine Boltzmann Maschine vor.
Es stellt ein Zwei-Ebenensystem dar, mit einem Inputlayer und einem Outputlayer, wo jeder Knoten mit jedem verbunden ist, außer mit sich selbst.
Das voll vernetzte System unterscheidet eine Boltzmann Maschine von einer eingeschränkten Boltzmann Maschine (RBM), welche eine Grundlage für tiefes Lernen und tiefe Neuronale Netzwerke darstellt.
In einer RBM sind alle sichtbaren Neuronen mit allen Neuronen im Outputlayer verbunden. 
Die Verbindungen zwischen den Neuronen im selben Layer entfallen.
Der alte uneingeschränkte Typ der Boltzmann Maschinen eignet sich gut für Optimierungsprobleme sowie für Mustererkennungen.

\subsection{Deep FeedForward}
\label{subsec:DeepFeedForward}

Deep FeedForward Netzwerke unterscheiden sich von den normalen FeedForward Netzwerken in dem, dass sie mehrere Hiddenlayer beinhalten anstatt nur einem.

\subsection{NEAT}

NeuroEvolution of Augmenting Topologies (NEAT) Netzwerke sind relativ jung, wobei NEAT für einen Algorithmus steht, der Neuronale Netzwerke entwickelt.
Er wurde von Stanley und Miikkulainen (2002) entwickelt. 
Dieser Typ verwendet genetische Algorithmen, um die Struktur und die Gewichtungen im Netzwerk zu optimieren.
Die Input- und Outputlayer sind identisch mit einem FeedForward Netzwerk.
Dafür fehlt diesem Typ eine innere Struktur. 
Die Verbindungen sind lose, nicht klar definiert und können während dem Trainieren entfernt werden, aber auch wieder hinzugefügt werden.

\subsection{Convolutional Neural Network}

Convolutional Neural Network werden selbst nicht als komplettes eigenes Netzwerk verwendet, sondern in FeedForward Netzwerken.
Im Speziellen, wenn es um Bilderkennung geht.
Dabei werden zwei Ebenen nicht voll vernetzt sondern nur teilweise und somit Gewichtungen eingespart.
Außerdem können die Gewichtungen geteilt werden, sodass immer in dieselbe Richtung verlaufende Verbindungen dieselbe Gewichtung aufweisen.
Dies ermöglicht es, komplexe Strukturen zu speichern und trotzdem die Speicherauslastung niedrig zu halten und die Effektivität aufrecht zu halten.

\subsection{Recurrent Network}

Recurrent Network sind Netzwerke, die nicht nur einen Kontrollfluss haben, sondern auch Rekursionen beinhalten. 
Diese Rekursionen können jedes andere Neuron ansprechen, ausgenommen der Neuronen im Inputlayer.
Ein Problem durch Rekursionen sind Endlosschleifen, welche behandelt werden müssen.
So können Kontext-Neuronen verwendet werden, aber auch eine definierte Anzahl an Iterationen durchlaufen werden, damit die Rekursion nicht mehr fortgeführt wird. 
Eine weitere Option ist so lange zu warten, bis sich die Ausgabe des Neurons stabilisiert hat und sich nicht mehr ändert.
Das Kontext-Neuron nimmt dabei die Stelle eines kurzen Speichers ein, wo ein Zustand für die nächste Iteration zwischengespeichert wird.
Die Informationen, die in einem solchen Neuron gespeichert werden, werden bei diesem Speichervorgang nicht gewichtet, sondern erst, wenn diese Informationen an das Netzwerk zurückgegeben werden.
Diese Rekursionen werden vor allem in Fällen verwendet, wenn es um zeitliche Abläufe und Änderungen geht, wie zum Beispiel bei der Temperatur für den nächsten Tag, hierfür stehen etliche Daten vorangegangener Jahre zur Verfügung.

\paragraph{Elman Network} wurde im Jahre 1990 vorgestellt, sie verwenden Rekursionen mit Kontext-Neuronen. 
Dabei existieren zwei Hiddenlayer mit einem Layer für normale Neuronen und einem mit Kontext-Neuronen. 
Die Kontext-Neuronen sind dabei voll mit dem Hiddenlayer verbunden und dieser gibt die Informationen ungewichtet an die Kontext-Neuronen weiter.
In diesem System existieren so viele Kontext-Neuronen wie Neuronen im Hiddenlayer, sodass jedes Neuron dort ein Kontext-Neuron mit dem neuen Status befüllt.

\paragraph{Jordan Network} wurde 1993 der Öffentlichkeit präsentiert.
Sie sind den Elman Netzwerken sehr ähnlich. 
Es werden wieder Kontext-Neuronen für das Zwischenspeichern verwendet, nur wird dieser Zustand durch den Outputlayer definiert.
So wird der Ausgang gespeichert und in der nächsten Iteration wieder verwendet.
Das Kontext-Neuron ist dabei nur mit dem Outputlayer wieder verbunden und nicht mit einem Hiddenlayer.

\section{Domänen und Typen Matrix}

\begin{figure}
	\includegraphics[scale=0.68]{images/typen_domains.png}
	\caption{Domänen zu Typen Matrix \cite{AI3}}
	\label{fig:DomainMatrix}
\end{figure}

Wie in Abbildung \ref{fig:DomainMatrix} erkennbar ist, existiert kein Netzwerkgrundtyp, der für alle Problemdomänen geeignet ist.
Dies führt zu der Schlussfolgerung, dass je nach Aufgabe und Ziel ein entsprechendes Grundgerüst gewählt werden muss. 
Auf Basis dieses Grundgerüsts können uneingeschränkt weitere Eigenheiten aus anderen Netzwerken eingebaut werden.
In der Praxis findet man selten ein Netzwerk von nur einem Typ für eine größere Problemstellung. 
Das Problem wird auf mehrere kleinere Problemstellungen herabgebrochen, welche hintereinander und teilweise parallel gelöst werden.
Dabei übernimmt jedes Teilnetzwerk eine kleine Aufgabe des Gesamten und zwar die eine, für die es entwickelt wurde. 
Aktuelle Netzwerke wie das 'Inception v3' Netzwerk von Google Research benötigen zwei Wochen mit acht Grafikkarten zum Trainieren. 
Ab diesem Zeitpunkt ist es im Stande, akkurate Resultate zu liefern. 
Dieses Netzwerk ist sehr komplex und besteht nicht nur aus 3 Ebenen, was zur Schlussfolgerung führt, dass je tiefer das Netzwerk ist, desto aufwändiger ist es zu trainieren.

\section{Optimierung}

Optimierungen beeinflussen das Lernverhalten und das Speicherverhalten eines Netzwerkes.

\paragraph{Lernrate} skaliert die Lerngeschwindigkeit, wie im Punkt Backpropagation beschrieben.

\paragraph{Momentum} gehört auch zur Optimierung im Algorithmus zur Backpropa-gation.
Dieser bestimmt wie stark frühere Gewichtsaktualisierungen berücksichtigt werden sollen. 

\paragraph{DropOut} gehört zur Kategorie der Regulatoren. 
Hinton \cite{krizhevsky2012imagenet} beschreibt DropOuts als eine effektive Art, um Overfitting zu vermeiden.
DropOut kann als System integriert werden, aber auch als eigener Layer in einem Netzwerk.
In einem DropOutlayer werden immer Neuronen deaktiviert, inklusive ihrer Verbindungen zum nächsten Layer.
Dies hat zur Folge, dass nur ein geringerer Teil an Informationen aus dem vorhergehenden Layer in den nächsten übergeht. 
Der Prozess des künstlichen Geringhaltens von Informationen während des Trainings führt dazu, dass das Netzwerk trotz dieser Einschränkung versucht, ein gutes Ergebnis zu erzielen. 
Während der Test- und Produktivphase werden diese DropOutlayer aber meist deaktiviert, da das volle Potenzial des Netzwerks verwendet werden soll.

\paragraph{L1 und L2 Regularisierung} sind ebenfalls Techniken, die zur Verhinderung von Overfitting beitragen.
Im Gegensatz zu der DropOut Strategie sind diese zwei Regularisierungstechniken Teil der Backpropagation oder werden als Funktion eingesetzt.
Beide Techniken arbeiten mit Strafen, welche verteilt werden und so die Gewichtungen vor dem Ausarten hindern. 
Durch das Bestrafen der Gewichtungen im Netzwerk werden diese Werte gering gehalten. 
Wenn ein Gewicht Richtung $0$ geht, führt dies unweigerlich zu einem indirekten Ausschluss aus dem Netzwerk. 
Das Netzwerk wird spärlicher und leichtgewichtiger, sodass ein Rauschen in den Daten ignoriert wird. 

\begin{equation}
	E := \frac{\lambda}{n} \sum |w|
	\label{eq:L1ErrorTerm}
\end{equation}

\noindent
Die Funktion \ref{eq:L1ErrorTerm} bildet die Berechnung der Strafe in der Backpropagation ab.
Das $\lambda$ definiert wie stark die Regularisierung den Error-Wert des Netzwerkes beeinflussen soll.
Ein Wert von $0$ führt dazu, dass die Regularisierung keinen Einfluss besitzt. 
Im einem normalen Fall ist dieser Wert kleiner als $0.1 (10\%)$.
Der Divisor n wird durch die Anzahl an Elementen im Trainingssatz und der Anzahl an Neuronen im Outputlayer bestimmt.
Zum Beispiel bei $100$ Elementen im Trainingssatz und $3$ Neuronen im Outputlayer würde der Divisor den Wert $300$ einnehmen.
Dies ist erforderlich, da diese Funktion bei jeder Evaluierung der Trainingsdaten berechnet wird.

\section{Trainingsgeschwindigkeitssteigerung}

\paragraph{GPU - GPGPU} ist die Bezeichnung für die Verwendung des Grafikprozessors über seine ursprüngliche Auslegung darüber hinaus.
In der aktuellen Zeit ist es nicht mehr möglich, eine Geschwindigkeitssteigerung zu erreichen, indem die Taktrate des Prozessors erhöht wird. 
Deshalb wird mehr parallelisiert, da die Recheneinheiten kleiner werden und so mehrere auf derselben Fläche Platz finden. 
Eine Grafikkarte besitzt die Eigenschaft, gleichförmige Operationen in einem Schritt auf sehr viele Objekte gleichzeitig auszuführen. 
So werden viele Pixel auf einmal eingefärbt oder eine Multiplikation großer Matrizen durchgeführt. 
Der Geschwindigkeitsvorteil kommt dabei durch den hohen Grad an Parallelität, da die Grafikkarte hauptsächlich für solche Operationen ausgelegt worden ist.

\paragraph{Batch Learning} 
führt dazu, dass immer ein Paket an Daten in das System eingeführt wird. 
Dieses Paket wird je nach Implementierung parallel verarbeitet oder sequenziell. 
Der Unterschied zu 'Online Learning' ist nun, dass nicht nach jedem Datensatz die Gewichtungen und das System nachjustiert wird, sondern dass zuerst das Paket verarbeitet und das System einmal angepasst wird. 
Dabei werden die Gradienten zusammengerechnet und einmal auf den Graphen adaptiert \cite{AI3}. 