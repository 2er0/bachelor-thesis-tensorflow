# Machine Learning und tiefe neuronale Netze mit TensorFlow

Bachelor thesis, David Baumgartner, [UNIVERSITY OF APPLIED SCIENCES UPPER AUSTRIA](https://www.fh-ooe.at/campus-hagenberg/), 2017

## Kurzfassung

Neuronale Netzwerke werden seit Jahrzehnten erforscht und auch seit geraumer Zeit eingesetzt. 
Solche Netzwerke ermöglichen es, komplexe Systeme für logisch sehr komplexe Aufgaben zu entwickeln. 
Zum Beispiel werden bei der Übersetzung von Texten in Bildern neuronale Netzwerke eingesetzt. 
Diese Ausführung geschieht dabei zum Teil auf den Smartphones lokal. 
Eine lokale Ausführung war dabei nicht immer möglich, da die dafür benötigten Ressourcen nicht vorhanden waren. 
Zu Beginn der Erforschung von neuronalen Netzwerken konnten nur Modelle erstellt werden. 
Modelle wurden deshalb herangezogen, da die technischen Voraussetzungen noch nicht gegeben waren. 
Mit der Entwicklung von integrierten Schaltkreisen und immer leistungsfähigeren Recheneinheiten konnte diese Grundlage geschaffen werden. 
Dabei existieren noch Probleme, denn ein maschinell lernendes System muss trainiert werden. 
Ein solches Training kann zum Beispiel mit einem Schwimmer verglichen werden, der einen neuen Technikablauf integrieren möchte. 
So ein Vorgang benötigt viel Zeit bis der Ablauf adaptiert wird und im Anschluss fast vollautomatisch abläuft. 
Ähnlich geht es den neuronalen Netzwerken, welche anhand des Ergebnisses angepasst werden müssen. 
Der Einzug von maschinell lernenden Systemen in die Zivilgesellschaft ist dank ihres Erfolgs praktisch unumgänglich. 

Im Rahmen dieser Bachelorarbeit wurde ein Beispiel anhand realer Daten umgesetzt und implementiert. 
An diesem Beispiel werden einige Eigenheiten solcher Systeme erklärt und beschrieben. 
Zusätzlich beinhaltet diese Arbeit auch eine Einführung in das Gebiet der neuronalen Netzwerke. 
Diese Grundlagen werden mit Hilfe der Bibliothek **TensorFlow** vervollständigt. 
TensorFlow bietet eine guten Einstieg, damit die Grundlagen besser und praktischer verstanden werden. 
Technisch nicht so versierte Personen sollten nach dem Erlernen der Grundlagen deshalb eine Abstraktion verwenden, wie zum Beispiel **Keras**.

## Abstract

Neuronal networks have been reasearched for decades and are growing in commercial usage. 
They make it possibility to create systems that can solve very complex problems, e.g. the translation of pictures to text. \footnote{Google Translate app: [https://research.googleblog.com/2015/07/how-google-translate-squeezes-deep.html](https://research.googleblog.com/2015/07/how-google-translate-squeezes-deep.html) 
Such systems need computational power which was not available in former times. 
So at the start there were only models and today we can do that nearly on our smartphones. 
The development of integrated circuits enabled more research and a more efficient development in that research area. 
But these systems need more computational power for training than our smartphones currently have. 
For the training there is time needed to adapt and recognize patterns, like a swimmer how wants to adapt a new technique to be more efficient. 
In general all these systems get more and more evolved and are reaching a level where they are simultaneously integrated in our daily life. 

The present thesis includes an example with real data which was developed to visualize a problem and how it could be solved. 
Additionally the work contains an introduction to the topic of neuronal networks, it's basics and the basic math behind it. 
By applying the basics to the framework **TensorFlow**, it will get more practical and understandable. 
For people who are technically not experienced, frameworks like **Keras** exist. 

## License

**Thesis, Code & Slides:** [GPL v3](LICENSE)

## File Index

* [PDF-Version](Bachelorarbeit_DavidBaumgartner_2017.pdf) 
* [Thesis](thesis)
* [Slides](slides)